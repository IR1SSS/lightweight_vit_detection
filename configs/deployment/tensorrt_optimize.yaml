# TensorRT Optimization Configuration
# 轻量化视觉Transformer实时物体检测系统 - TensorRT优化配置
# 预留配置文件，后续实现

tensorrt:
  # 输入ONNX模型
  onnx_path: "outputs/exports/mobilevit_detection.onnx"
  
  # 输出TensorRT引擎
  engine_path: "outputs/exports/mobilevit_detection.engine"
  
  # 构建配置
  builder:
    max_batch_size: 8
    max_workspace_size: 1073741824  # 1GB
    
  # 精度配置
  precision:
    mode: "fp16"  # fp32, fp16, int8
    
    # INT8量化配置
    int8:
      enabled: false
      calibration_dataset: "data/coco/val2017"
      calibration_batch_size: 8
      calibration_batches: 100
      cache_file: "outputs/calibration_cache.bin"
      
  # 输入配置
  input:
    name: "input"
    min_shape: [1, 3, 320, 320]
    opt_shape: [1, 3, 640, 640]
    max_shape: [8, 3, 640, 640]
    
  # 优化选项
  optimization:
    layer_device_types: true
    strict_types: false
    profile_verbose: true
